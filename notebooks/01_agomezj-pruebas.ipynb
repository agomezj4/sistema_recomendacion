{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import sys\n",
    "import yaml\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../src/')\n",
    "project_root = os.path.dirname(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorios para los archivos de parámetros y los datos\n",
    "parameters_directory = os.path.join(project_root, 'src', 'parameters')\n",
    "data_raw_directory = os.path.join(project_root, 'data', 'raw')\n",
    "data_processed_directory = os.path.join(project_root, 'data', 'processed')\n",
    "data_features_directory = os.path.join(project_root, 'data', 'featured')\n",
    "data_train_directory = os.path.join(project_root, 'data', 'model_input', 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista todos los archivos YAML en el directorio especificado\n",
    "yaml_files = [f for f in os.listdir(parameters_directory) if f.endswith('.yml')]\n",
    "\n",
    "# Diccionario para guardar los parámetros cargados\n",
    "parameters = {}\n",
    "\n",
    "# Carga cada archivo YAML\n",
    "for yaml_file in yaml_files:\n",
    "    with open(os.path.join(parameters_directory, yaml_file), 'r') as file:\n",
    "        data = yaml.safe_load(file)\n",
    "        key_name = f'parameters_{yaml_file.replace(\".yml\", \"\")}'\n",
    "        parameters[key_name] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROCESSING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Nodos\n",
    "# from functions.processing import (validate_tags_pl, \n",
    "#                              validate_dtypes_pl, \n",
    "#                              change_names_pl, \n",
    "#                              change_dtype_pl,\n",
    "#                              delete_accents_pl,\n",
    "#                              standardize_binary_values_pl,\n",
    "#                              impute_missing_values_pl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag_dict_path = os.path.join(data_raw_directory, parameters['parameters_catalog']['tag_dict_path'])\n",
    "# raw_data_path = os.path.join(data_raw_directory, parameters['parameters_catalog']['raw_data_path'])\n",
    "# \n",
    "# tag_dict = pl.read_excel(tag_dict_path)\n",
    "# data_raw = pl.read_csv(raw_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba1 = validate_tags_pl(data_raw, tag_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba2 = validate_dtypes_pl(prueba1, tag_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba3 = change_names_pl(prueba2, tag_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba4 = change_dtype_pl(prueba3, tag_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba5 = delete_accents_pl(prueba4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba6 = standardize_binary_values_pl(prueba5, parameters['parameters_processing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba7 = impute_missing_values_pl(prueba6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FEATURING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Nodos\n",
    "# from functions.featuring import (new_features_pl,\n",
    "#                                  add_target_variable_pl,\n",
    "#                                  one_hot_encoding_pl,\n",
    "#                                  random_forest_selection_pl,\n",
    "#                                  conditional_entropy_selection_pl,\n",
    "#                                  intersect_top_features_pl)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_data_path = os.path.join(data_processed_directory, parameters['parameters_catalog']['processed_data_path'])\n",
    "#\n",
    "# data_processed = pl.read_csv(processed_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba8 = new_features_pl(data_processed, parameters['parameters_featuring'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_directory = os.path.join(project_root, 'data', 'processed')\n",
    "# target_path = os.path.join(target_directory, parameters['parameters_catalog']['target_column_path'])\n",
    "# target = pl.read_csv(target_path)\n",
    "# prueba9 = add_target_variable_pl(prueba8, target, parameters['parameters_featuring'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba10 = one_hot_encoding_pl(prueba9, parameters['parameters_featuring'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba11 = random_forest_selection_pl(prueba10, parameters['parameters_featuring'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba12 = conditional_entropy_selection_pl(prueba10, parameters['parameters_featuring'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba13 = intersect_top_features_pl(prueba11, prueba12, prueba10, parameters['parameters_featuring'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL INPUT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Nodos\n",
    "# from functions.model_input import (min_max_scaler_pl,\n",
    "#                                    balance_target_variable_pl,\n",
    "#                                    train_test_split_pl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# featured_data_path = os.path.join(data_features_directory, parameters['parameters_catalog']['features_data_path'])\n",
    "#\n",
    "# data_featured = pl.read_csv(featured_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba14 = min_max_scaler_pl(data_featured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba15 = balance_target_variable_pl(prueba14, parameters['parameters_model_input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba16 = train_test_split_pl(prueba15, parameters['parameters_model_input'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Nodos\n",
    "from functions.models import (train_models_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = os.path.join(data_train_directory, parameters['parameters_catalog']['train_data_path'])\n",
    "\n",
    "train_data = pd.read_csv(train_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:functions.models:Inicio del entrenamiento y evaluación de modelos...\n",
      "\n",
      "INFO:functions.models:Evaluando modelos básicos...\n",
      "\n",
      "INFO:functions.models:Entrenando y evaluando el modelo: Logistic Regression (basic_models)\n",
      "INFO:functions.models:Pipeline(steps=[('classifier',\n",
      "                 LogisticRegression(C=0.1, max_iter=1000, random_state=42,\n",
      "                                    solver='liblinear'))])\n",
      "\n",
      "INFO:functions.models:Entrenando y evaluando el modelo: SVM (basic_models)\n",
      "INFO:functions.models:Pipeline(steps=[('classifier', SVC(random_state=42))])\n",
      "\n",
      "INFO:functions.models:Entrenando y evaluando el modelo: KNN (basic_models)\n",
      "INFO:functions.models:Pipeline(steps=[('classifier', KNeighborsClassifier())])\n",
      "\n",
      "INFO:functions.models:Entrenando y evaluando el modelo: Decision Tree (basic_models)\n",
      "INFO:functions.models:Pipeline(steps=[('classifier',\n",
      "                 DecisionTreeClassifier(max_depth=4, random_state=42))])\n",
      "\n",
      "INFO:functions.models:Evaluando modelos ensemble...\n",
      "\n",
      "INFO:functions.models:Entrenando y evaluando el modelo: Random Forest (ensemble_models)\n",
      "INFO:functions.models:Pipeline(steps=[('classifier',\n",
      "                 RandomForestClassifier(max_depth=4, random_state=42))])\n",
      "\n",
      "INFO:functions.models:Entrenando y evaluando el modelo: AdaBoost (ensemble_models)\n",
      "INFO:functions.models:Pipeline(steps=[('classifier',\n",
      "                 AdaBoostClassifier(algorithm='SAMME', learning_rate=0.1,\n",
      "                                    n_estimators=100, random_state=42))])\n",
      "\n",
      "INFO:functions.models:Entrenando y evaluando el modelo: XGBoost (ensemble_models)\n",
      "INFO:functions.models:Pipeline(steps=[('classifier',\n",
      "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=None, device=None,\n",
      "                               early_stopping_rounds=None,\n",
      "                               enable_categorical=False, eval_metric=None,\n",
      "                               feature_types=None, gamma=None, grow_policy=None,\n",
      "                               importance_type=None,\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_bin=None, max_cat_threshold=None,\n",
      "                               max_cat_to_onehot=None, max_delta_step=None,\n",
      "                               max_depth=4, max_leaves=None,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, multi_strategy=None,\n",
      "                               n_estimators=100, n_jobs=None,\n",
      "                               num_parallel_tree=None, random_state=42, ...))])\n",
      "\n",
      "INFO:functions.models:Análisis de rendimiento para la métrica: accuracy\n",
      "INFO:functions.models:Comparando los siguientes modelos usando la métrica accuracy: KNN, Decision Tree, SVM, Logistic Regression\n",
      "INFO:functions.models:Hipótesis nula: Los modelos tienen el mismo rendimiento.\n",
      "INFO:functions.models:Estadístico de Friedman: 64.90268456375841\n",
      "P-value: 5.2623020601674044e-14\n",
      "INFO:functions.models:Como el valor P es menor que 0.05 (5.2623020601674044e-14); se rechaza la hipótesis nula:\n",
      "Se encontraron diferencias estadísticamente significativas entre los modelos.\n",
      "INFO:functions.models:Resumen de la prueba post-hoc de Nemenyi para la métrica 'accuracy':\n",
      "                         Mean    Median\n",
      "KNN                  0.816716  0.817727\n",
      "Decision Tree        0.770130  0.769895\n",
      "SVM                  0.764311  0.763810\n",
      "Logistic Regression  0.763977  0.762619\n",
      "\n",
      "INFO:functions.models:Comparando los siguientes modelos usando la métrica accuracy: XGBoost, Random Forest, AdaBoost\n",
      "INFO:functions.models:Hipótesis nula: Los modelos tienen el mismo rendimiento.\n",
      "INFO:functions.models:Estadístico de Friedman: 60.0\n",
      "P-value: 9.357622968840163e-14\n",
      "INFO:functions.models:Como el valor P es menor que 0.05 (9.357622968840163e-14); se rechaza la hipótesis nula:\n",
      "Se encontraron diferencias estadísticamente significativas entre los modelos.\n",
      "INFO:functions.models:Resumen de la prueba post-hoc de Nemenyi para la métrica 'accuracy':\n",
      "                   Mean    Median\n",
      "XGBoost        0.823779  0.821737\n",
      "Random Forest  0.771100  0.770402\n",
      "AdaBoost       0.756400  0.756081\n",
      "\n",
      "INFO:functions.models:Análisis de rendimiento para la métrica: precision\n",
      "INFO:functions.models:Comparando los siguientes modelos usando la métrica precision: Decision Tree, Logistic Regression, SVM, KNN\n",
      "INFO:functions.models:Hipótesis nula: Los modelos tienen el mismo rendimiento.\n",
      "INFO:functions.models:Estadístico de Friedman: 84.27999999999997\n",
      "P-value: 3.7042230236602006e-18\n",
      "INFO:functions.models:Como el valor P es menor que 0.05 (3.7042230236602006e-18); se rechaza la hipótesis nula:\n",
      "Se encontraron diferencias estadísticamente significativas entre los modelos.\n",
      "INFO:functions.models:Resumen de la prueba post-hoc de Nemenyi para la métrica 'precision':\n",
      "                         Mean    Median\n",
      "Decision Tree        0.814739  0.816029\n",
      "Logistic Regression  0.756308  0.758673\n",
      "SVM                  0.745095  0.744516\n",
      "KNN                  0.729705  0.730312\n",
      "\n",
      "INFO:functions.models:Comparando los siguientes modelos usando la métrica precision: XGBoost, Random Forest, AdaBoost\n",
      "INFO:functions.models:Hipótesis nula: Los modelos tienen el mismo rendimiento.\n",
      "INFO:functions.models:Estadístico de Friedman: 46.666666666666686\n",
      "P-value: 7.35295806145377e-11\n",
      "INFO:functions.models:Como el valor P es menor que 0.05 (7.35295806145377e-11); se rechaza la hipótesis nula:\n",
      "Se encontraron diferencias estadísticamente significativas entre los modelos.\n",
      "INFO:functions.models:Resumen de la prueba post-hoc de Nemenyi para la métrica 'precision':\n",
      "                   Mean    Median\n",
      "XGBoost        0.855448  0.855740\n",
      "Random Forest  0.813529  0.816815\n",
      "AdaBoost       0.811639  0.812369\n",
      "\n",
      "INFO:functions.models:Análisis de rendimiento para la métrica: recall\n",
      "INFO:functions.models:Comparando los siguientes modelos usando la métrica recall: KNN, SVM, Logistic Regression, Decision Tree\n",
      "INFO:functions.models:Hipótesis nula: Los modelos tienen el mismo rendimiento.\n",
      "INFO:functions.models:Estadístico de Friedman: 90.0\n",
      "P-value: 2.190570119285308e-19\n",
      "INFO:functions.models:Como el valor P es menor que 0.05 (2.190570119285308e-19); se rechaza la hipótesis nula:\n",
      "Se encontraron diferencias estadísticamente significativas entre los modelos.\n",
      "INFO:functions.models:Resumen de la prueba post-hoc de Nemenyi para la métrica 'recall':\n",
      "                         Mean    Median\n",
      "KNN                  0.849494  0.849972\n",
      "SVM                  0.610922  0.611080\n",
      "Logistic Regression  0.591802  0.589152\n",
      "Decision Tree        0.539168  0.540681\n",
      "\n",
      "INFO:functions.models:Comparando los siguientes modelos usando la métrica recall: XGBoost, Random Forest, AdaBoost\n",
      "INFO:functions.models:Hipótesis nula: Los modelos tienen el mismo rendimiento.\n",
      "INFO:functions.models:Estadístico de Friedman: 60.0\n",
      "P-value: 9.357622968840163e-14\n",
      "INFO:functions.models:Como el valor P es menor que 0.05 (9.357622968840163e-14); se rechaza la hipótesis nula:\n",
      "Se encontraron diferencias estadísticamente significativas entre los modelos.\n",
      "INFO:functions.models:Resumen de la prueba post-hoc de Nemenyi para la métrica 'recall':\n",
      "                   Mean    Median\n",
      "XGBoost        0.665208  0.665127\n",
      "Random Forest  0.543709  0.543303\n",
      "AdaBoost       0.497080  0.498270\n",
      "\n",
      "INFO:functions.models:Análisis de rendimiento para la métrica: f1\n",
      "INFO:functions.models:Comparando los siguientes modelos usando la métrica f1: KNN, SVM, Logistic Regression, Decision Tree\n",
      "INFO:functions.models:Hipótesis nula: Los modelos tienen el mismo rendimiento.\n",
      "INFO:functions.models:Estadístico de Friedman: 86.51999999999998\n",
      "P-value: 1.2242055752782812e-18\n",
      "INFO:functions.models:Como el valor P es menor que 0.05 (1.2242055752782812e-18); se rechaza la hipótesis nula:\n",
      "Se encontraron diferencias estadísticamente significativas entre los modelos.\n",
      "INFO:functions.models:Resumen de la prueba post-hoc de Nemenyi para la métrica 'f1':\n",
      "                         Mean    Median\n",
      "KNN                  0.785006  0.787473\n",
      "SVM                  0.671257  0.669594\n",
      "Logistic Regression  0.663887  0.663666\n",
      "Decision Tree        0.648767  0.650952\n",
      "\n",
      "INFO:functions.models:Comparando los siguientes modelos usando la métrica f1: XGBoost, Random Forest, AdaBoost\n",
      "INFO:functions.models:Hipótesis nula: Los modelos tienen el mismo rendimiento.\n",
      "INFO:functions.models:Estadístico de Friedman: 60.0\n",
      "P-value: 9.357622968840163e-14\n",
      "INFO:functions.models:Como el valor P es menor que 0.05 (9.357622968840163e-14); se rechaza la hipótesis nula:\n",
      "Se encontraron diferencias estadísticamente significativas entre los modelos.\n",
      "INFO:functions.models:Resumen de la prueba post-hoc de Nemenyi para la métrica 'f1':\n",
      "                   Mean    Median\n",
      "XGBoost        0.748317  0.746737\n",
      "Random Forest  0.651576  0.651634\n",
      "AdaBoost       0.616428  0.615214\n",
      "\n",
      "INFO:functions.models:Los mejores modelos son: KNN (básico) y XGBoost (ensemble)\n",
      "\n",
      "INFO:functions.models:Entrenamiento y evaluación de modelos completado!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prueba17 = train_models_pd(train_data, parameters['parameters_models'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KNN'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prueba17['basic']['model_name'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'XGBoost'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prueba17['ensemble']['model_name'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
